{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import xarray as xr\n",
    "import glob\n",
    "from toolz import *\n",
    "\n",
    "from gnl.calculus import c_grid_advective_tendency\n",
    "from uwnet.thermo import get_dz\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "%opts Image [colorbar=True, width=400, height=300](cmap='viridis'){+axiswise +framewise}\n",
    "\n",
    "\n",
    "class config:\n",
    "    workdir = \"/Users/noah/Data/0/\"\n",
    "\n",
    "def to_normal_units_nn_columns(ds):\n",
    "    \"\"\"Convert output from uwnet.columns to have proper SI units\"\"\"\n",
    "    scales = {\n",
    "        'FQT': 1 / 86400 / 1000,\n",
    "        'FSL': 1 / 86400,\n",
    "        'Q1NN': 1 / 86400 / 1000,\n",
    "        'qt': 1 / 1000,\n",
    "        'qtOBS': 1 / 1000,\n",
    "        'Q2NN': 1 / 86400 / 1000,\n",
    "        'QN': 1/1000,\n",
    "        'QP': 1/1000\n",
    "    }\n",
    "\n",
    "    for key, scale in scales.items():\n",
    "        if key in ds:\n",
    "            ds = ds.assign(**{key: ds[key] * scale})\n",
    "\n",
    "    return ds\n",
    "\n",
    "def compute_divergence(state):\n",
    "\n",
    "\n",
    "    u, v, w = get('U V W'.split(), state)\n",
    "    dx  = float(ds.x[1]-ds.x[0])\n",
    "    dz = get_dz(ds.z).values\n",
    "    rho = state['layer_mass'] / dz\n",
    "    f = np.ones_like(u)\n",
    "\n",
    "    hdiv = c_grid_advective_tendency(u, v, 0*w, f, dx, dz, rho)\n",
    "    vdiv = c_grid_advective_tendency(0*u, 0*v, w, f, dx, dz, rho)\n",
    "    \n",
    "    return hdiv, vdiv\n",
    "\n",
    "\n",
    "def compute_advection_tendency(state, key):\n",
    "    u, v, w = get('U V W'.split(), state)\n",
    "    dx  = float(ds.x[1]-ds.x[0])\n",
    "    dz = get_dz(ds.z).values\n",
    "    rho = state['layer_mass'] / dz\n",
    "    return  c_grid_advective_tendency(u, v, w, pkl[key], dx, dz, rho)\n",
    "\n",
    "\n",
    "def mass_integral(x, w):\n",
    "    y = x * np.reshape(w, (-1, 1, 1))\n",
    "    return y.sum(axis=-3)\n",
    "\n",
    "\n",
    "def load_data(id):\n",
    "    # load data\n",
    "    \n",
    "    pattern = config.workdir + id + '*/NG1_test_*.pkl'\n",
    "    print(pattern)\n",
    "    pkls = [merge(torch.load(f).values())\n",
    "            for f in  glob.glob(pattern)]\n",
    "    ds = xr.open_zarr(\"../data/training_data.zarr/\").pipe(to_normal_units_nn_columns)\n",
    "    return pkls, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_cwp_id(id):\n",
    "\n",
    "    pkls, ds = load_data(id)\n",
    "\n",
    "    pkl = pkls[0]\n",
    "\n",
    "    cwp = mass_integral(pkl['QN'], pkl['layer_mass'])\n",
    "    plt.pcolormesh(cwp)\n",
    "    plt.colorbar()\n",
    "    plt.figure()\n",
    "    (ds.QN[0] * ds.layer_mass).sum('z').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cwp_id(\"86/462bf2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted CWP is very different between the simulations. The neural network really struggles to predict this quantity correctly. It does okay in the tropics, but not elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkls, ds = load_data(\"c0/d2a5df\")\n",
    "print(len(pkls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap = hv.HoloMap(kdims=['field', 'y'])\n",
    "\n",
    "\n",
    "for j in [10, 20 ,32]:\n",
    "    for key in 'qt sl U V W'.split():\n",
    "        x = pkls[0][key][:,j,0]\n",
    "        y = ds[key].isel(y=j,x=0,time=0).values\n",
    "\n",
    "        elm = hv.Curve(x-y, label='truth')\n",
    "        hmap[(key, j)] = elm\n",
    "    \n",
    "hmap.opts({'Curve': {'norm': dict(framewise=True, axiswise=True)}}).layout('field')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cwp_id(\"c0/d2a5df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the differences are not that big. I am suprised it make such a difference. The error in the temperature is significant I guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay I need to do more debugging. I should generate a case which makes a very small time step and see\n",
    "\n",
    "1. Do TABS, QV, QN, QP change at all\n",
    "2. Are the inputs to the NN identical to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SAM for 3 time steps with very small time step\n",
    "\n",
    "The basic state should not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "\n",
    "caseid = \"NG1_2018-08-15-A\"\n",
    "\n",
    "def open_ic_and_case(caseid, sam_dir=config.sam):\n",
    "    \"\"\"Open initial condition and 3d output files for SAM\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ic : initial condition\n",
    "    ds : 3d output of SAM\n",
    "    \"\"\"\n",
    "    ic = xr.open_dataset(sam_dir + \"/NG1/ic.nc\")\n",
    "    ds  = open_case(caseid)\n",
    "    ic = ic.assign_coords(x=ds.x, y=ds.y)\n",
    "    \n",
    "    return ic, ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import curry\n",
    "\n",
    "\n",
    "def compare_ds_with_ic(ic, ds, field, t):\n",
    "    return ic[field], ds[field].sel(time=t)\n",
    "\n",
    "\n",
    "@curry\n",
    "def image_comparison(ic, ds, field, t, z):\n",
    "    x,y = compare_ds_with_ic(ic, ds, field, t)\n",
    "    return hv.Image((y-x).sel(z=z))\n",
    "\n",
    "\n",
    "\n",
    "def concat_kind(ds, ic):\n",
    "    common_vars = list(set(ic.data_vars) & set(ds.data_vars))\n",
    "    return xr.concat((ic[common_vars], ds[common_vars]), dim=pd.Index(['NG', 'SAM'], name='kind'))\n",
    "\n",
    "\n",
    "def case_visualizer(caseid, t=0):\n",
    "    ic, ds = open_ic_and_case(caseid)\n",
    "    ds = ds.isel(time=t)\n",
    "\n",
    "    return concat_kind(ds, ic).to_array(dim='field')\\\n",
    "    .pipe(hv.Dataset)\\\n",
    "    .to.image([\"x\", \"y\"], dynamic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this it looks like the vapor and condensate fields disagree from the very outset, but that QP and the temperature are pretty close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that QN is identically zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image[width=300, height=200] {+axiswise}\n",
    "case_visualizer(\"NG1_2018-08-15-A\", t=1).grid([\"kind\", \"field\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good these look identical. Now, I can safely call the neural network from within SAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN in SAM\n",
    "\n",
    "\n",
    "Calling NN in sam, but there are problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_debug(path):\n",
    "    return [torch.load(f)['kwargs'] for f in  glob.glob(f\"{path}*/NG1_test_*.pkl\")]\n",
    "\n",
    "\n",
    "def plot_rel_error_z(x, y):\n",
    "    ans = np.sqrt(((x-y)**2).mean(['x', 'y']))\n",
    "    ans = ans / np.sqrt((x**2).mean(['x', 'y'])) \n",
    "    return hv.Curve(ans)\n",
    "\n",
    "def norm_3d(x, y, w):\n",
    "    return float(((x-y)**2*w).mean().pipe(np.sqrt))\n",
    "\n",
    "def rel_error_3d(x, y, w):\n",
    "    return norm_3d(x, y, w)/norm_3d(x, 0, w)\n",
    "\n",
    "\n",
    "id = \"90/ad19f6\"\n",
    "pkls= open_debug(config.nextflow_workdir + id)\n",
    "ic = xr.open_mfdataset(config.nextflow_workdir + id + \"*/NG1/ic.nc\")\n",
    "ds = xr.open_zarr(\"../data/training_data.zarr\").sel(time=ic.time).pipe(to_normal_units_nn_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap = hv.HoloMap({key: plot_rel_error_z(ds[key],  pkls[0][key])\n",
    "                   for key in 'sl qt FQT FSL U V W'.split()})\n",
    "hmap.layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very large relative errors in the forcing fields, and smaller errors in the velocity field and temperature field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rel_error_report(id):\n",
    "    pkls= open_debug(config.nextflow_workdir + id)\n",
    "    ic = xr.open_mfdataset(config.nextflow_workdir + id + \"*/NG1/ic.nc\")\n",
    "    ds = xr.open_zarr(\"../data/training_data.zarr\").sel(time=ic.time).pipe(to_normal_units_nn_columns)\n",
    "    \n",
    "    rel_errors = {key: norm_3d(ds[key], pkls[0][key], ds.layer_mass)\n",
    "               for key in 'sl qt FQT FSL U V W'.split()}\n",
    "    return rel_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rel_error_report(\"90/ad19f6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the problem with the velocities, or is it with the way SAM is computing FSL given U, V, W? Let's recompute FQT using the same routine used to get the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.FQT.mean(['x']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = xr.open_zarr(\"../data/training_data.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds.FSL[0].mean(['x']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsl = xr.DataArray(pkls[0]['FSL'], dims=training_ds.FSL[0].dims, coords=training_ds.FSL[0].coords)\n",
    "fsl.mean(['x']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this actually looks pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnl.calculus import c_grid_advective_tendency\n",
    "from uwnet.thermo import get_dz\n",
    "\n",
    "\n",
    "def compute_advection_tendency(state, key, z, x):\n",
    "    u, v, w = get('U V W'.split(), state)\n",
    "    dx  = float(x[1]-x[0])\n",
    "    dz = get_dz(z).values\n",
    "\n",
    "    rho = state['layer_mass'] / dz\n",
    "    return  c_grid_advective_tendency(u, v, w, state[key], dx, dz, rho)\n",
    "\n",
    "FSL_adv = compute_advection_tendency(pkls[0], 'sl', ds.z, ds.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_error_3d(fsl, FSL_adv, ds.layer_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image{-axiswise -framewise}\n",
    "\n",
    "hmap = hv.HoloMap({\n",
    "    'Computed from advection': hv.Image(FSL_adv[:,32,:]),\n",
    "    'Training Data': hv.Image(ds.FSL[:,32,:].values),\n",
    "    'SAM': hv.Image(pkls[0]['FSL'][:,32,:])\n",
    "})\n",
    "\n",
    "hmap.layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain mean FQT, FSL and W do not vanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(86400*ds.FSL.mean(['x', 'y'])).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(86400*FSL_adv.mean(axis=(-1,-2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds.W.mean(axis=(-2,-1)), label='mu')\n",
    "# plt.plot(ds.W.std(axis=(-2,-1)), label='sig')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain mean vertical velocity does not vanish in the training data. This is some kind of mistake. This does not seem to be a problem with the coarse-graining. because averaging the high resolution results in a similar domain mean vertical velocity profile.\n",
    "\n",
    "Is the average vertical velocity closer to zero after one time step with SAM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pkls[1]['W'].mean(axis=(-2,-1)))\n",
    "plt.plot(pkls[0]['W'].mean(axis=(-2,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vertical velocity measured with SAM is actually much smaller. Perhaps this is a result of the pressure correction step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM implements the divergence free condition\n",
    "\n",
    "Does the coarse-resolution data I have respect SAMs divergence free condition? I could check this by seeing if the SAM changes the velocity field after a very short time step. This is the same experiment as run [above](#Run-SAM-for-3-time-steps-with-very-small-time-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_axes=True]\n",
    "\n",
    "caseid = \"NG1_2018-08-15-A\"\n",
    "ic, ds = open_ic_and_case(caseid)\n",
    "\n",
    "hv.Curve(ic.W.mean(['x', 'y']), label='Initial cond.') \\\n",
    "* hv.Curve(ds.W[1].mean(['x', 'y']), label='After 1 timestep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed we can see that the domain mean vertical velocity vanishes after one time step, which means the pressure correction is active. Maybe `write_fields_3d` happens after the model updates the velocity, and runs the pressure correction step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute advection tendency using divergent free winds\n",
    "\n",
    "I can use SAM to produce a divergence free velocity field by taking one very small time step and saving the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam.case import pressure_correct\n",
    "\n",
    "ic_p = pressure_correct(ic, sam_src=config.sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain mean vertical velocity of this should vanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Curve(ic_p.W.mean(['x', 'y'])[0])\\\n",
    "* hv.Curve(ic.W.mean(['x', 'y']), label='Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the advection tendency using this pressure corrected velocity field seems to improve things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts  Raster[invert_yaxis=True](cmap='RdBu_r'){-axiswise -framewise}\n",
    "\n",
    "\n",
    "# compute avection tendency\n",
    "ic_p['layer_mass'] = training_ds.layer_mass\n",
    "ic_p_dict = {key: val.values for key, val in ic_p.variables.items()}\n",
    "ic_p_dict['sl'] = training_ds['sl'][0]\n",
    "fsl_pressure_corrected = compute_advection_tendency(ic_p_dict, 'sl', training_ds.z, ic_p['x'])\n",
    "\n",
    "# visualize it\n",
    "vals = {\n",
    "     'Computed from advection': FSL_adv[:,32,:],\n",
    "    'Training Data': training_ds.FSL[0,:,32,:].values/86400,\n",
    "    'SAM': pkls[0]['FSL'][:,32,:],\n",
    "    'Pressure Corrected': fsl_pressure_corrected[0,:,32,:]\n",
    "}\n",
    "\n",
    "\n",
    "hmap = hv.HoloMap({key: hv.Raster(val, kdims=['x index', 'z index']) for key, val in vals.items()})\n",
    "hmap.layout().cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the domain mean of FSL is also much smaller (although not exactly zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_axes=True]\n",
    "\n",
    "lay = hv.Curve(fsl_pressure_corrected[0].mean(axis=(-2,-1))*86400, kdims=['z'], vdims=['FSL'], label='Pressure Corrected ') * \\\n",
    "hv.Curve(training_ds.FSL[0].mean(['x', 'y']).values, kdims=['z'], label='Training Data FSL')\n",
    "\n",
    "lay.redim.unit(FSL='K/day', z='index').relabel(\"Domain mean FSL\") \\\n",
    "+ hv.Curve(training_ds.z.values).redim.label(x='index', y='z').redim.unit(z='m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
