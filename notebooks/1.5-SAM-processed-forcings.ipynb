{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the problems with incompressibility and other things, I have completely changed the strategy for the training dataset, in this notebook I will analyze the new version of the forcing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import torch\n",
    "import glob\n",
    "from collections.abc import Mapping\n",
    "from holoviews import streams\n",
    "hv.extension('bokeh')\n",
    "%opts Image[colorbar=True, invert_yaxis=True, width=500, height=200] (cmap='viridis') {+framewise +axiswise}\n",
    "%opts Raster[colorbar=True, invert_yaxis=True, width=500, height=200] (cmap='viridis') {+framewise +axiswise}\n",
    "%opts QuadMesh[colorbar=True, invert_yaxis=True, width=500, height=200] (cmap='viridis') {+framewise +axiswise}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"../data/training_data.nc\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a typical grid point on the tropics (x,y) = (0,32)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ds.isel(x=0,y=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[width=500, height=100]\n",
    "lay=  hv.Raster(loc.FQT.values.T, label='FQT')  + hv.Raster(loc.FSLI.values.T, label='FSLI') \\\n",
    "+ hv.Curve(loc.Prec.values, vdims=['Prec'])\n",
    "lay.cols(1).redim(x='time', z='c', y='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this new data does not have the banding artifact near the boundary layer. What about the zonal mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = ds.mean(['x', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay =  hv.Raster(mu.FSLI.values, label='FSLI') + hv.Raster(mu.FQT.values, label='FQT')\n",
    "lay.cols(1).redim(x='y', z='c', y='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still is some strange artifacts near the edge of the domain for FSLI, but that is not unexpected. The humidity forcing looks better. Maybe there are still some bugs in how I'm computing temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizontal momentum tendencies\n",
    "\n",
    "These are also kind of strange. I am not sure if these are physical or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Raster[width=400, height=200]{+axiswise}\n",
    "\n",
    "fields = ['U', 'V', 'FV', 'FU']\n",
    "hmap = hv.HoloMap({key: hv.Raster(mu[key].values) for key in fields}).redim(z='c', x='y', y='z')\n",
    "hmap.layout().cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with debugging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 'deadly_becquerel'\n",
    "path = f'../data/samNN/{id}/NG1_test_0000002.pkl'\n",
    "\n",
    "\n",
    "def norm(x):\n",
    "    return np.sqrt((x**2).mean(axis=(-1,-2)))\n",
    "\n",
    "# get first debugging point\n",
    "dbg = torch.load(f'../data/samNN/{id}/NG1_test_0000001.pkl')\n",
    "state, dt = dbg['args']\n",
    "\n",
    "# get first time point\n",
    "ds = xr.open_dataset(\"../data/training_data.nc\").isel(time=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(ds.W-state['W']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(ds['FQT']-state['FQT']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(norm(ds['FSLI']-state['FSLI'])*86400).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(norm(ds['FQT']-state['FQT'])*86400).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still a big discrepency in FQT and FSL in the first time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.FQT[5].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_like(x, y):\n",
    "    if isinstance(x, Mapping):\n",
    "\n",
    "        keys = set(x) & set(y.data_vars)\n",
    "        return xr.Dataset({key: index_like(x[key], y[key]) for key in keys})\n",
    "    else:\n",
    "        if x.shape[0] == 1:\n",
    "            x = x[0]\n",
    "        return xr.DataArray(x, dims=y.dims, coords=y.coords)\n",
    "    \n",
    "    \n",
    "def open_debug_state_like_ds(path: str, ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\"Open SAM debugging output as xarray object\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path\n",
    "        path to pickle saved by torch\n",
    "    ds\n",
    "        dataset to use a template\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    state\n",
    "        dataset with fields from path\n",
    "    \"\"\"\n",
    "    dbg = torch.load(path)\n",
    "    state = dbg['args'][0]\n",
    "    out = dbg['out']\n",
    "    return index_like(state, ds)\n",
    "\n",
    "\n",
    "def concat_datasets(args, name='mode'):\n",
    "    \"\"\"Concatenate datasets with a new named index\n",
    "    \n",
    "    This function is especially useful for comparing two datasets with\n",
    "    shared variables with holoviews\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : list\n",
    "        list of (name, dataset) pairs\n",
    "    name : str\n",
    "        name of the new dimension\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ds : xr.Dataset\n",
    "        concatenated data\n",
    "    \"\"\"\n",
    "    \n",
    "    names, vals = zip(*args)\n",
    "    \n",
    "    # get list of vars\n",
    "    vars = set(vals[0])\n",
    "    for val in vals:\n",
    "        vars = vars & set(val)\n",
    "    vars = list(vars)\n",
    "    \n",
    "    vals = [val[vars] for val in vals]\n",
    "        \n",
    "    return xr.concat(vals, dim=pd.Index(names, name=name))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 4\n",
    "path = glob.glob(f'../data/samNN/{id}/NG1_test_0000*.pkl')[i]\n",
    "dbg = open_debug_state_like_ds(path, ds)\n",
    "cds = concat_datasets([('DBG', dbg),('Train', ds)], name='source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dbg:\n",
    "    if dbg[key].ndim > 1:\n",
    "        print(norm(dbg[key]-ds[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these should be identically zero. That they are not indicates some problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_axes=True] {+framewise}\n",
    "\n",
    "variables_to_plot = [ 'FSLI', 'FQT','SLI', 'QT', 'W', 'U']\n",
    "data_to_plot = cds[variables_to_plot].to_array(dim='variable', name='value')\n",
    "\n",
    "\n",
    "hv.Dataset(data_to_plot).to.curve(\"z\", dynamic=True)\\\n",
    "  .overlay(\"source\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The debugging and training data are mostly similar although not identical. However, the neural network should hopefully not be sensitive to these types of small differences. I need to check, but I suspect the problem is that the network is simply too sensitive to FQT and FSLI. Now that I have ironed out many of the issues with the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are some points with extremely different points. Here is a little interface for exploring the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_axes=True] {+framewise}\n",
    "\n",
    "variables_to_plot = [ 'FSLI', 'FQT','SLI', 'QT', 'W', 'U']\n",
    "data_to_plot = cds[variables_to_plot].to_array(dim='variable', name='value')\n",
    "\n",
    "\n",
    "def curves( x, y):\n",
    "    if None in [x, y]:\n",
    "        x, y = (0,0)\n",
    "        \n",
    "    return hv.Dataset(cds['W'].sel(x=x, y=y, method='nearest')).to.curve(\"z\").overlay(\"source\")\n",
    "    \n",
    "\n",
    "\n",
    "w_im = hv.Image(ds.Prec)\n",
    "# pointer = streams.SingleTap(transient=True, source=w_im)\n",
    "pointer = streams.PointerXY(x=0,y=0, source=w_im)\n",
    "\n",
    "\n",
    "dmap = hv.DynamicMap(curves, kdims=['x', 'y'], streams=[pointer]).redim.values(key=variables_to_plot)\n",
    "\n",
    "\n",
    "dmap.select(key='W').redim.range(W=(-.3, .3))  +  w_im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
