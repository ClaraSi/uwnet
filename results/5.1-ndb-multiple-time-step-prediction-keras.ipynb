{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are using are only evaulated with a coarse sampling time step of 3 hours. On the other hand, we will probably use 10-20 minute time step for the coarse resolution model. This means that the dynamical model we are trying to fit is \n",
    "$$ x^i_{n+1} = \\underbrace{f(f(\\ldots f}_{\\text{m times}}(x^i_n))) + \\int_{t_n}^{t_{n+1}} g(x(t), t) dt$$ \n",
    "where $i$ is the horizontal spatial index, and $n$ is the time step. The number of times the function $f$ is applied is $m=\\frac{\\Delta t}{h}$ where $h$ is the GCMs time step, and $\\Delta t$ is the sampling interval of the stored output. The integral on the right represents the approximately known terms such as advection, and $f$ represents the unknown source terms.\n",
    "\n",
    "We solve a minimization problem to find $f$. This is given by \n",
    "$$\n",
    "\\min_{a} \\lim_{m \\rightarrow \\infty} \\sum_{i,n} ||x^{i}_{n+1} - F^{(m)} x^i_{n} - g_n^{i}||_W^2 \\quad \\text{s.t.}\\quad F^{(m)}(\\cdot) = \\underbrace{f(f(\\ldots f}_{\\text{m times}}(\\cdot))),\\ f(x) = x +  \\frac{ \\Delta t}{m} a(x).\n",
    "$$\n",
    "Intuitively, the forward operator $F^{(m)}$ is the result applying $m$ forward euler steps to the system $a$.\n",
    "\n",
    "Let's try performing this fit. First, we need to import the appropriate models, and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the coarse sampling time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = float(X.time[1] - X.time[0])*86400\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many 10 minute time steps are in this period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt//(60*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../data/ml/ngaqua/time_series_data.npz\")\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "G = data['G']\n",
    "scale = data['scales']\n",
    "w = data['w']\n",
    "\n",
    "scale_weight = w/scale**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we apply this once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
