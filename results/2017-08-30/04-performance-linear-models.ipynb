{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputs": [
     "ml/x.npz",
     "ml/y.npz"
    ]
   },
   "outputs": [],
   "source": [
    "def get_data(d):\n",
    "    x = np.load(f\"{d}/x.npz\")['arr_0']\n",
    "    y = np.load(f\"{d}/y.npz\")['arr_0']\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "x, y= get_data(\"ml\")\n",
    "\n",
    "\n",
    "# maybe transform data\n",
    "\n",
    "def transform(y, tht=45):\n",
    "    return np.arcsinh(y*tht)/tht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import probplot\n",
    "\n",
    "\n",
    "yr = np.random.choice(y.ravel(), 10000, replace=False)\n",
    "probplot(transform(yr, 45), plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45 seems like a reasonable value for the transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x.shape[0]\n",
    "percent_train = .6\n",
    "ntrain = int(percent_train * n)\n",
    "\n",
    "train_idx = np.arange(ntrain)\n",
    "test_idx = np.arange(ntrain, n)\n",
    "\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_test, y_test = x[test_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCA prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_mod_xform(mod):\n",
    "    tht = 10\n",
    "    z_train = np.arcsinh(tht*y_train)/tht\n",
    "    zt = mod.fit(x_train, z_train).predict(x_test)\n",
    "    yt = np.sinh(zt*tht)/tht\n",
    "    return r2_score(y_test, yt, multioutput=\"variance_weighted\")\n",
    "\n",
    "def score_mod(mod):\n",
    "    return mod.fit(x_train, y_train).score(x_test, y_test)\n",
    "\n",
    "\n",
    "def plot_coef(mod):\n",
    "    I = np.eye(x.shape[1])\n",
    "    coef= mod.predict(I)\n",
    "    plt.pcolormesh(coef)\n",
    "    plt.colorbar()\n",
    "\n",
    "def summarize_performance(mod):\n",
    "    r2_xform = score_mod_xform(mod)\n",
    "    r2 = score_mod(mod)\n",
    "    plot_coef(mod)\n",
    "    \n",
    "    print(f\"R2 = {r2}; arcsinh r2 = {r2_xform}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mca import MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = make_pipeline(MCA(60), LinearRegression(fit_intercept=False))\n",
    "summarize_performance(mca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = make_pipeline(MCA(10), LinearRegression(fit_intercept=False))\n",
    "summarize_performance(mca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_performance(Ridge(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "summarize_performance(PLSRegression(10, scale=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TruncatedSVD(40), LinearRegression())\n",
    "summarize_performance(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this it seems that the maximum covariance analysis returns the most accurate results it only does so when an extreme number of modes is used, but to my eye the linear response function obtained by ridge regression is the most plausible since it smooth. The other methdos all have visible oscillatory phenomena. Maybe partial least squares will work better if run in a different mode, but it is the most computationally expensive algorithm of the three. \n",
    "\n",
    "Also, taking the arcsinh transform does not appear to help either. It seems the extreme convection events cannot be captured well by generalized linear models."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
