{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability of Single Column Models\n",
    "\n",
    "In this section I evaluate the stability of the single layer perceptron models (SLP) in a single column setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "\n",
    "from lib.models.torch_models import predict\n",
    "from lib.models.torch_models import train_euler_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the coarse sampling time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 3/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../data/ml/ngaqua/time_series_data.npz\")\n",
    "\n",
    "\n",
    "X = data['X']\n",
    "G = data['G']\n",
    "scale = data['scales']\n",
    "w = data['w']\n",
    "\n",
    "# we need to grap the pressure field from a different path\n",
    "p = xr.open_dataset(\"../data/raw/ngaqua/stat.nc\").p.values\n",
    "t = dt * np.arange(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract qt, sl and the advection terms for one specific horizonal location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[:-1,8,0,:]\n",
    "xp = X[1:, 8,0,:]\n",
    "g = G[:-1,8,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some simple plotting routines\n",
    "\n",
    "def plot_t(t, x):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.pcolormesh(t, p, x[:,:34].T, cmap='inferno')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I plot the observed $Q_{1}$, which is defined as \n",
    "\n",
    "$$\\frac{s_l^{n+1} - s_l^{n}}{\\Delta t} - g_{s_l}^n, $$\n",
    "where $g_{s_l}$ are the horizontal and vertical advection of $s_l$, which we approximate using centered differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_t(t, (xp-x)/dt-g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outside of this notebok, I have trained a neural network model with this data, and I load it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(\"../data/ml/ngaqua/time_series_fit.torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the networks predicted $Q_1$ looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_q1 = predict(net, x)\n",
    "plot_t(t, predicted_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to do a pretty good job compared to the truth above. So we seem to be reaching some sort of **consistency**. However, we also have to check the **stability** of the scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single column tests of the model.\n",
    "\n",
    "## Initial value problem\n",
    "\n",
    "Let's start some reference profile and integrate the model forward without any advection terms. If the scheme is unstable then we will need to rethink the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple function which we will use to integrate our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_time_series(predict, x0, nsteps):\n",
    "    out = np.empty((nsteps+1, x0.shape[0]))\n",
    "    out[0] = x0\n",
    "    x = x0\n",
    "    for i in range(nsteps+1):\n",
    "        x = predict(x)\n",
    "        out[i] = x\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when we take 20 forward euler time steps using our scheme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = run_time_series(lambda x: x + predict(net, x)*.125,  x[0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_t(t[1:21], ts[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the scheme is very unstable, and the scheme just gives NaNs after 8 time steps . The white Which is not good. Can we assess the instability of a scheme somehow without actually running it? Once solution is to use a global fit.\n",
    "\n",
    "Soem sort of rayleigh quotient should work. Here is one definition: $\\frac{x' \\cdot f(x' + \\bar{x})}{x'\\cdot x'}$, where $x$ is the concatenated vertical profiles of $q_T$ and $s_L$ as usual, and $\\bar{x}$ is the time mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rayleigh_quotient(f, x, axis=-1):\n",
    "    fx = f(x)\n",
    "    return np.sum(x * fx, axis=axis)/np.sum(x * x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x.mean(axis=0)\n",
    "x_pert = x-x_mean\n",
    "\n",
    "r = rayleigh_quotient(lambda x: predict(net, x+x_mean), x_pert)\n",
    "plt.plot(r)\n",
    "plt.axhline(0.0, c='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the scheme is mostly stable over the observed training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened when we used the neural network model in a predictive mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rayleigh_quotient(lambda x: predict(net, x+x_mean), ts-x_mean)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that scheme somehow became extremely unstable. But how was this possible after only 1 time step, so let's just look at the first two time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x[0]\n",
    "x1 = x0 + predict(net, x0) * .125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_yaxis=True, ] {+axiswise}\n",
    "\n",
    "hv.Curve((x0[34:], p)) * hv.Curve((x1[34:], p))\n",
    "\n",
    "holomap = hv.HoloMap({\n",
    "    ('qt', 0): hv.Curve((x0[34:], p), vdims=['p']),\n",
    "    ('qt', 1): hv.Curve((x1[34:], p), vdims=['p']),\n",
    "    ('sl', 0): hv.Curve((x0[:34], p), vdims=['p']),\n",
    "    ('sl', 1): hv.Curve((x1[:34], p), vdims=['p'])},\n",
    "kdims=['variable', 'step'])\n",
    "\n",
    "holomap.overlay(\"step\").layout(\"variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the intial profile and the profile after 1 step are nearly overlapping. What are the rayleigh coefficients of each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rayleigh_quotient(lambda x: predict(net, x+x_mean), x0-x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rayleigh_quotient(lambda x: predict(net, x+x_mean), x1-x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it that the rayleigh coefficient is so drastically different for such a small change? Let's look at the different in the predicted heating profiles. Is it because our network is overfitting? Is this an artifact of the code in this particular section?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_yaxis=True, ] {+axiswise}\n",
    "\n",
    "\n",
    "hv.HoloMap({\n",
    "    0: hv.Curve((predict(net, x0)[:34], p), vdims=['Q1']),\n",
    "    1: hv.Curve((predict(net, x1)[:34], p), vdims=['Q1'])\n",
    "}, kdims=['step']).layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the profiles are drastically different! It is very strange that such slightly different profiles can lead to such radically different predicted heating profiles!\n",
    "\n",
    "It is strange that this happens. Overfitting might cause the network to generalize so poorly, but the cross validation score for this network is actually pretty good.\n",
    "\n",
    "In any case, this example demonstrates that **consistency** as measured by the R2 score of predicting $Q1$ and $Q2$ does not ensure that the scheme is **accurate**. We also need to make sure the network is **stable**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
