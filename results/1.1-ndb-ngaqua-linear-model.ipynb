{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import holoviews as hv\n",
    "# hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import  tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.curried import *\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from xnoah.sklearn import Normalizer, Stacker, Select, Weighter\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "mem = joblib.Memory(\"../data/cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = xr.open_mfdataset(\"../data/ngaqua/3d/*.nc\")\n",
    "D2= xr.open_mfdataset(\"../data/ngaqua/2d/*.nc\")\n",
    "w = xr.open_dataarray(\"../data/processed/ngaqua/w.nc\")\n",
    "p = xr.open_dataset(\"../data/ngaqua/stat.nc\").p\n",
    "\n",
    "D = D.merge(D2, join='inner')\n",
    "D = D.assign(Q1c=D.Q1 - D.QRAD)\n",
    "\n",
    "\n",
    "d_train, d_test= D.sel(time=slice(0,50)), D.sel(time=slice(50,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = make_union(\n",
    "    make_pipeline(Select('QT', sel={'z': slice(0,10e3)}), Normalizer(['x', 'y', 'time']), Stacker(['x', 'y', 'time'])),\n",
    "    make_pipeline(Select('SL'), Normalizer(['x', 'y', 'time']), Stacker(['x', 'y', 'time'])),\n",
    "    make_pipeline(Select('SHF'), Normalizer(['x', 'y', 'time']), Stacker(['x', 'y', 'time'])),\n",
    "    make_pipeline(Select('LHF'), Normalizer(['x', 'y', 'time']), Stacker(['x', 'y', 'time'])),\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "output_union = make_union(\n",
    "    make_pipeline(Select('Q1c'), Weighter(np.sqrt(w)), Stacker(['x', 'y', 'time'])),\n",
    "    make_pipeline(Select('Q2'), Weighter(np.sqrt(w)), Stacker(['x', 'y', 'time']))\n",
    ")\n",
    "\n",
    "\n",
    "mod = make_pipeline(union, LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the condition number of the input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat = union.fit_transform(d_train)\n",
    "np.linalg.cond(design_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This low value shows that we can expect a linear regression to perform reasonably well. Now let's fit for this matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = union.fit_transform(D)\n",
    "y_test = output_union.fit_transform(d_test)\n",
    "y_train = output_union.fit_transform(d_train)\n",
    "\n",
    "x_train = union.fit_transform(d_train)\n",
    "x_test = union.fit_transform(d_test)\n",
    "\n",
    "mod.fit(d_train, y_train)\n",
    "mod.score(d_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%timeit LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%timeit mod.fit(d_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.score(d_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 performance on the testing portion is not as good as on the training portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of trying to fit all of y at once, let's fit an independent model for each output feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted = [mod.fit(d_train, y) for y in  y_train.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from dask.delayed import delayed\n",
    "from dask.distributed import Client\n",
    "\n",
    "try:\n",
    "    client\n",
    "except NameError:\n",
    "    client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mem.cache(verbose=False)\n",
    "def fit_score(mod, x_train, y_train, x_test, y_test):\n",
    "    mod.fit(x_train, y_train)\n",
    "    score = mod.score(x_test, y_test)\n",
    "    \n",
    "    return mod, score\n",
    "\n",
    "@mem.cache\n",
    "def fit_all_mods(mod, x_train, y_train, x_test, y_test):\n",
    "    return [fit_score(mod, x_train, y, x_test, yt) for y, yt in tqdm(list(zip(y_train.T, y_test.T)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods= fit_all_mods(LinearRegression(), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array(list(map(nth(1), mods)))\n",
    "p1, p2 = np.split(scores, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_axes=True invert_yaxis=True width=250 ] Overlay[legend_position=\"top_left\"]\n",
    "\n",
    "\n",
    "def _mycurve(p, y, label=None):\n",
    "    return hv.Curve((p, y), label=label, kdims=['p'], vdims=['R2'])\n",
    "\n",
    "_mycurve(p,p1, label='Q1') * _mycurve(p,p2, label='Q2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the fit performs worst in the midtroposphere. This is probably due to the noiseness of deep convection compared to shallow and stratiform convection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Deviations of Data\n",
    "\n",
    "Is the linear model fit bad just because it is in regions with high variance? This appears to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = d_train.std(['x', 'y', 'time']).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts  Curve[invert_axes=True invert_yaxis=True shared_axes=False fontsize=fontsize aspect=.4] {+axiswise}\n",
    "\n",
    "hv.NdLayout({k: hv.Curve((p, sig[k]), kdims=['p']) for k in sig.data_vars\n",
    "           if  sig[k].ndim==1}, kdims=['sig']).cols(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
