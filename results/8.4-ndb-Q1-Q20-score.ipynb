{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.models.torch import interface\n",
    "from lib.advection import vertical_advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_residual(x, f):\n",
    "    dt = x.time[1]-x.time[0]\n",
    "    return (f-f.shift(time=-1))/dt - f\n",
    "\n",
    "\n",
    "def compute_residuals(inputs, forcings):\n",
    "    \"\"\"Compute Q1 and Q2\"\"\"\n",
    "    ds = xr.Dataset({key: _compute_residual(inputs[key], forcings[key])\n",
    "                for key in ['qt', 'sl']})\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_srcs(src, resid, **kw):\n",
    "    \"\"\"Compare the x and time averaged source terms\"\"\"\n",
    "    \n",
    "    kw.update(dict(x=\"y\", y=\"z\"))\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(8, 6), sharey=True, sharex=True)\n",
    "    src.sl.mean(['x', 'time']).plot(ax=axs[0,0], **kw)\n",
    "    resid.sl.mean(['x', 'time']).plot(ax=axs[0,1], **kw)\n",
    "\n",
    "\n",
    "    src.qt.mean(['x', 'time']).plot(ax=axs[1,0], **kw)\n",
    "    resid.qt.mean(['x', 'time']).plot(ax=axs[1,1], **kw)\n",
    "\n",
    "    for ax, title in zip(axs.flat,[\"NN Q1\", \"Q1\", \"NN Q2\", \"Q2\"]):\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = xr.open_dataset(\"../data/processed/inputs.nc\")\n",
    "forcings = xr.open_dataset(\"../data/processed/forcings.nc\")\n",
    "\n",
    "resid = compute_residuals(inputs, forcings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../data/output/model.test/1.torch\")\n",
    "src = interface.rhs(model, inputs, forcings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_srcs(src, resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some very big differences between the prediction and the observed residuals. I bet this is because I perform this verification without first adding the forcing term. The actual time stepping taken by the neural network looks like\n",
    "$$ x^* = x^n + \\frac{h}{2}(g^{n+1} + g^n),\\quad x^{n+1} = x^* + h f(x^*) $$\n",
    "where $g^n$ is the advection forcing at time step $n$. There are probably very big splitting errors because I am using $h=3$ hours, which means that the statistics of $x^*$ might be very different from the statistics of $x^n$. This could have a large impact on the output of the neural network. To do this let's first apply the advection terms to the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trapezoid_step(x, g, h=.125):\n",
    "    return x + h * (g + g.shift(time=1))/2\n",
    "\n",
    "xst = inputs.apply(lambda x: trapezoid_step(x, forcings[x.name]) if x.name in ['sl', 'qt'] else x)\n",
    "gavg = (forcings + forcings.shift(time=1))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the mean of $x^*$ and $x^n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = xst.mean(['x', 'time']) - inputs.mean(['x', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (aq, at)  = plt.subplots(1, 2, figsize=(8,3), sharey=True)\n",
    "\n",
    "bias.qt.plot(ax=aq)\n",
    "bias.sl.plot(ax=at)\n",
    "\n",
    "aq.set_title(\"QT diff (g/kg)\")\n",
    "aq.set_title(\"SL diff (K)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These differences are actually pretty small, so I would be surprised if they are causing the problem, but let's just see what the Neural network predicts the source terms will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = interface.rhs(model, xst, gavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_srcs(src, resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This made a big difference! It turns out the splitting error actually matters a lot in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = xr.open_dataset(\"../data/output/test_error.nc\")\n",
    "err= err.assign(qt64=(err.qt*err.w).mean('z'), sl64=(err.sl*err.w).mean('z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(stat, data, n=1000):\n",
    "    stats = []\n",
    "    for i in range(n):\n",
    "        sample = np.random.choice(data, data.shape[0])\n",
    "        stats.append(stat(sample))\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def get_ci(x, interval=(2.5, 97.5)):\n",
    "    samples = bootstrap(np.median, x)\n",
    "    a, b = np.percentile(samples, interval)\n",
    "    return np.median(x), (b-a)/2\n",
    "\n",
    "\n",
    "def get_cis(x):\n",
    "    return x.apply(get_ci, axis=0)\n",
    "\n",
    "\n",
    "def format_uncertain(x):\n",
    "    if x[0] > 1000:\n",
    "        return r'$\\infty$'\n",
    "    else:\n",
    "        return f\"{x[0]:.2f} ({x[1]:.2f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = err[['qtR2', 'slR2', 'qt64', 'sl64', 'nhidden', 'window_size']]\\\n",
    ".to_dataframe()\n",
    "\n",
    "\n",
    "df_with_ci = df.groupby(['nhidden', 'window_size'])\\\n",
    ".apply(get_cis)\\\n",
    ".drop('window_size', 1)\\\n",
    ".drop('nhidden', 1)\\\n",
    ".applymap(format_uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    ('qtR2',  (r'Apparent Source $R^2$', r'$q_T$')),\n",
    "    ('slR2',  (r'Apparent Source $R^2$', r'$s_L$')),\n",
    "    ('qt64',  (r'64 Step Error', r'$q_T$')),\n",
    "    ('sl64',  (r'64 Step Error', r'$s_L$')), \n",
    "]\n",
    "\n",
    "cols = pd.MultiIndex.from_tuples(dict(columns).values())\n",
    "df_with_ci.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_nhid = df_with_ci.loc[pd.IndexSlice[:, 10],:].reset_index()\\\n",
    ".drop('window_size', 1)\\\n",
    ".rename({\"nhidden\": r\"$n$\"}, axis=1)\n",
    "\n",
    "vary_t = df_with_ci.loc[pd.IndexSlice[128,:],:].reset_index()\\\n",
    ".drop('nhidden', 1)\\\n",
    ".rename({\"window_size\": r\"$T$\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_nhid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
