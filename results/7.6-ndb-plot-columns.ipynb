{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from xnoah import swap_coord\n",
    "from lib.plots import plot_soln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I load the truth, SCAM and NN single column datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truth\n",
    "truth = xr.open_dataset(\"../data/processed/inputs.nc\")\n",
    "force = xr.open_dataset(\"../data/processed/forcings.nc\")\n",
    "truth = truth.assign(prec=force.Prec)\n",
    "truth = swap_coord(truth, {'z': 'p'})\n",
    "\n",
    "# SCAM\n",
    "# cam = xr.open_dataset(\"../data/processed/iop/0-8/cam.nc\").squeeze()\\\n",
    "#         .sel(time=truth.time[:-10])\n",
    "\n",
    "def convert_time_to_days(time, t0=float(truth.time[0])):\n",
    "    return t0 + (time-time[0]).astype('timedelta64[s]').astype(float)/86400\n",
    "\n",
    "cam = xr.open_dataset(\"../data/processed/iop/0-8/cam.nc\").squeeze()\n",
    "cam = cam.assign_coords(time=convert_time_to_days(cam.time.values))\n",
    "cam = cam.assign(p=cam.lev, prec=(cam.PRECL + cam.PRECC)*1000*86400, qt=cam.Q*1000,\n",
    "                sl=cam['T'] + cam.Z3 * 9.81/1004)\n",
    "\n",
    "# neural network scheme\n",
    "nn_cols = xr.open_dataset(\"../data/output/columns.nc\").assign(p=truth.p)\n",
    "nn_cols = swap_coord(nn_cols, {'z': 'p'}).rename({'Prec': 'prec'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some routines that I will need to interpolate CAM's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def interp_np(x, pold, pnew, axis=-1):\n",
    "    return interp1d(pold, x, axis=axis, bounds_error=False)(pnew)\n",
    "\n",
    "def pressure_interp(x, pnew):\n",
    "    val = interp_np(x.values, x.p, pnew, axis=cam.sl.get_axis_num('p'))\n",
    "    coords = {}\n",
    "    coords.update(x.coords)\n",
    "    coords['p'] = pnew\n",
    "    dims = x.dims\n",
    "    return xr.DataArray(val, coords=coords, dims=dims)\n",
    "\n",
    "def pressure_interp_ds(ds, pnew):\n",
    "    def f(x):\n",
    "        if 'p' in x.dims:\n",
    "            return pressure_interp(x, pnew)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    return ds.apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column plots\n",
    "\n",
    "In this section I compare the observed time series for a given spatial location near the equator to the time series generated by forcing the neural network (NN) parametrization and the single column version of CAM.\n",
    "\n",
    "I use the three dimensional advective tendency and the surface fluxes to force both NN and CAM, I also tried to match the diurnal cycle between the runs, but I am not sure I did this perfectly yet.\n",
    "\n",
    "## SAM (Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_soln(truth.isel(x=0,y=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_soln(nn_cols.isel(x=0, y=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_soln(cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just comparing these by eye we can see the neural network scheme does a dramatically better job than CAM. In particular, CAM predicts far too little precipitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance on the temperature field is worse. For short times of around 1-2 days, the scheme does a good job, but there is a subsantial warm bias in the equilibrium of the neural network scheme and SCAM.\n",
    "\n",
    "However, for all cases SCAM does substantially worse than the NN scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biases in mean state (pres vs lat)\n",
    "\n",
    "In this section I look at the bias between the means of the neural network scheme and the time series from SAM. Running SCAM is quite expensive, so I have only run SCAM for the equatorial points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mean = nn_cols.mean(['x', 'time'])\n",
    "truth_mean = truth.mean(['x', 'time'])\n",
    "bias = (nn_mean - truth_mean)\n",
    "\n",
    "# change units of y\n",
    "y = (bias.y-np.median(bias.y))/1000\n",
    "bias['y'] = y\n",
    "nn_mean['y'] = y\n",
    "truth_mean['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pres_vs_lat(bias, ax, levels=np.arange(-5, 6)*.5, title=None):\n",
    "    im = ax.contourf(bias.y, bias.p, bias, levels, cmap='bwr', extend='both')\n",
    "\n",
    "    plt.colorbar(im, pad=.01, ax=ax)\n",
    "    ax.set_xlabel('y (km)')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    \n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(7,3), dpi=100, sharey=True)\n",
    "plot_pres_vs_lat(bias.qt, axs[0], title=\"Humidity bias (g/kg)\")\n",
    "plot_pres_vs_lat(bias.sl, axs[1], title=\"Temperature bias (K)\")\n",
    "plt.subplots_adjust(wspace=.02)\n",
    "axs[0].invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camprec = cam.prec.mean(['time', 'x'])\n",
    "\n",
    "plt.figure(figsize=(5, 5/1.61), dpi=100)\n",
    "truth_mean.prec.plot(label='Truth')\n",
    "(nn_mean.prec).plot(label='NN')\n",
    "\n",
    "# plt.scatter([0], [camprec], label='CAM')\n",
    "\n",
    "plt.ylabel('Prec (mm/day)')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plainly see that SCAM dramatically underpredicts the amount of rain. I am not sure why it is so small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biases in equilibrium state (equator)\n",
    "\n",
    "In this section I just show vertical profiles of the bias that NN and CAM have compared to the mean on the equator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias(field, ax=None, title=\"\", xlim=None, unit=None):\n",
    "    obs = truth[field].isel(y=7).mean(['time', 'x'])\n",
    "    qt_profs = [('CAM', cam[field].mean(['time', 'x'])),\n",
    "                ('NN', nn_cols[field].isel(y=7).mean(['time', 'x']))]\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(2,3), dpi=100)\n",
    "\n",
    "    for key, val in qt_profs:\n",
    "        ax.plot(val-obs, val.p, label=key)\n",
    "    ax.set_title(title, size=10)\n",
    "    if xlim:\n",
    "        ax.set_xlim(xlim)\n",
    "    if unit:\n",
    "        ax.set_xlabel(unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(4,3), dpi=100, sharey=True)\n",
    "\n",
    "plot_bias('qt', title='Total water bias', unit='g/kg',\n",
    "          ax=axs[0], xlim=[-.5, 2.5])\n",
    "plot_bias('sl', title='Temperature bias', unit='K',\n",
    "          ax=axs[1], xlim=[-1, 5])\n",
    "\n",
    "\n",
    "axs[0].invert_yaxis()\n",
    "axs[0].set_ylabel('p (hPa)')\n",
    "axs[1].legend()\n",
    "axs[1].set_ylim([1000, 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias of NN is much better than CAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error growth (equator)\n",
    "\n",
    "In this section, I plot the dynamic growth of errors after the beginning of the simulations. I do this to provide a more quantitative perspective on the pressure vs time series above.\n",
    "\n",
    "I compare the zonally averaged mean absolute deviation (MAD) for four different predictions\n",
    "\n",
    "1. MAD between the time series and its time and zonal mean. This measures the magnitude of the fluctuations about the climatology.\n",
    "2. Persistence forecast. This forecast assumes that humidity and temperature do not change over the course of the simulation. This gives us an estimate of the time-scale over which the fields change naturally.\n",
    "3. SCAM based prediction\n",
    "4. NN based prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(truth, pred, dims=('x',)):\n",
    "    return ((truth-pred).fillna(0.0)**2).mean(dims)\n",
    "\n",
    "def mean_absolute_dev(truth, pred, dims=('x',)):\n",
    "    return (truth-pred).fillna(0.0).apply(np.abs).mean(dims)\n",
    "\n",
    "\n",
    "prog_vars = ['sl', 'qt']\n",
    "truthp = truth[prog_vars]\n",
    "\n",
    "# means\n",
    "mu = truth[prog_vars].mean(['time'])\n",
    "munn = nn_cols[prog_vars].mean(['time'])\n",
    "truth0 = truth[prog_vars].isel(time=0)\n",
    "\n",
    "\n",
    "# mse of prediction\n",
    "mses = dict(\n",
    "    NN=mean_absolute_dev(truthp, nn_cols),\n",
    "    Mean=mean_absolute_dev(truthp, mu),\n",
    "    Persistence=mean_absolute_dev(truthp, truth0)\n",
    ")\n",
    "\n",
    "camp = pressure_interp_ds(cam[prog_vars], truth.p)\n",
    "cam_mse = mean_absolute_dev(camp, truthp.isel(y=7))\n",
    "\n",
    "\n",
    "# q_contours = np.arange(2)*11\n",
    "\n",
    "def plot_mses(mses, axs=None, label='', **kwargs):\n",
    "    if axs is None:\n",
    "        fig, axs =plt.subplots(2, 2, sharey=True, sharex=True, dpi=100,\n",
    "                              figsize=(6, 3.5))\n",
    "        \n",
    "    keys = ['Mean', 'Persistence', 'NN', 'CAM']\n",
    "    \n",
    "    for ax, key in zip(axs.flat, keys):\n",
    "        val = mses[key]\n",
    "        im = ax.contourf(val.time, val.p, val.T, **kwargs)\n",
    "\n",
    "        ax.text(.05, .8, key,\n",
    "                    transform=ax.transAxes,\n",
    "                    bbox=dict(color='white'))\n",
    "        \n",
    "    \n",
    "    axs[0,0].invert_yaxis()\n",
    "    axs[0,0].set_ylabel('p (hPa)')\n",
    "    axs[1,0].set_ylabel('p (hPa)')\n",
    "    \n",
    "    for ax in axs[1,:]:\n",
    "        ax.set_xlabel('days')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=.02, hspace=.02)\n",
    "    cb = plt.colorbar(im, ax=axs, pad=.01)\n",
    "    cb.set_label(label)\n",
    "    \n",
    "    return axs, cb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Humidity Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_meridional_average = {key: val.qt.isel(y=8).sel(time=slice(100, 120))\n",
    "                           for key, val in mses.items()}\n",
    "mses_meridional_average['CAM'] = cam_mse.qt.sel(time=slice(100, 120))\n",
    "\n",
    "_, cb = plot_mses(mses_meridional_average, levels=np.arange(11)*.25,\n",
    "                  extend='max',\n",
    "                  label='MAD (g/kg)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see errors grow much more slowly for NN than for the other quantities. In practice, the NN is able to predict around 5-7 days before it decays to the mean. This is much vetter than either the persistence forecast or CAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_sl_meridional_average = {key: val.sl.isel(y=0).sel(time=slice(100, 120))\n",
    "                           for key, val in mses.items()}\n",
    "mses_sl_meridional_average['CAM'] = cam_mse.sl.sel(time=slice(100, 120))\n",
    "\n",
    "plot_mses(mses_sl_meridional_average, levels=.5*np.arange(11), extend='max',\n",
    "          label='MAD (K)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature predicted by the NN diverges from the truth much faster that it does for the humidity. Some large biases in the temperature emerge in the NN and CAM schemes.  Moreover, it appears the neural network misses the diurnal cycle of temperature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
