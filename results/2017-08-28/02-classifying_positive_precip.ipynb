{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import xarray as xr\n",
    "from gnl.plots import loghist\n",
    "from gnl.xarray import xr2mat\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D    = xr.open_mfdataset([f\"../2017-08-12/wd/calc/{f}.nc\" for f in ['qt', 'sl']] )\n",
    "Prec = xr.open_dataarray(\"../2017-08-12/wd/A64/2d/Prec.nc\")\\\n",
    "         .reindex_like(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,_ = xr2mat(D, ['x', 'time'], ['z'])\n",
    "y = Prec.stack(samples=[\"x\", \"time\"]) > .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_split = 50\n",
    "\n",
    "Xtrain = X.sel(time=slice(40,50)).values\n",
    "ytrain = y.sel(time=slice(40,50)).values\n",
    "\n",
    "Xtest = X.sel(time=slice(50,None)).values\n",
    "ytest = y.sel(time=slice(50,None)).values\n",
    "\n",
    "# subindices for faster training\n",
    "inds = np.random.choice(Xtrain.shape[0], 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 50% of the spatio temporal samples are less than .001 mm/day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = LogisticRegression()\n",
    "\n",
    "mod.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for C in [.0001, .001, .01, .1, 1.0,10.0,100.0]:\n",
    "    mod.set_params(C=C)\n",
    "    mod.fit(Xtrain, ytrain)\n",
    "    score = mod.score(Xtest, ytest)\n",
    "    print(f\"C = {C}, score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best testing performance is around 82% accuracy for the logistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(4)\n",
    "pca.fit(Xtrain)\n",
    "\n",
    "\n",
    "ztrain = pca.transform(Xtrain)\n",
    "\n",
    "mod = RandomForestClassifier(n_estimators=20)\n",
    "mod.fit(ztrain, ytrain)\n",
    "\n",
    "mod.score(pca.transform(Xtest), ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests really benefit from transforming the data first using PCA. The classification error is about 60% without this. I think random forests are too sensitive to basis used to describe the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is pretty slow for large numbers of samples. This is because its cost scales quadratically with the number of samples, it needs to copmute a pairwise distance matrix between each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod =  SVC()\n",
    "mod.fit(Xtrain[:1000], ytrain[:1000])\n",
    "\n",
    "mod.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural netowrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlayers = 3\n",
    "nhidden = 10\n",
    "\n",
    "for alpha in [.0001, .001, .01, .1, 1, 2]:\n",
    "    \n",
    "\n",
    "    net = MLPClassifier(hidden_layer_sizes=[nhidden]*nlayers, alpha=alpha)\n",
    "    net.fit(Xtrain[inds], ytrain[inds])\n",
    "    score = net.score(Xtest, ytest)\n",
    "    print(f\"alpha = {alpha}, score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like 81-82% test-accuracy is the best performance we are getting from any of these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the structures the neural network has learned. These are the first layers weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(net.coefs_[0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look similar to the vertical modes generated by the PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key question**: How does this compare to the trigger of a traditional deep convection scheme?\n",
    "\n",
    "Also, is the neural network more robust to using a wide variety of training data. This is what I would expect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
