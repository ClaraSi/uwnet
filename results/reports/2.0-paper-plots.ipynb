{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-process-(2-fig)\" data-toc-modified-id=\"Training-process-(2-fig)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training process (2 fig)</a></span></li><li><span><a href=\"#Diagnostic-Results-(1-2-figs)\" data-toc-modified-id=\"Diagnostic-Results-(1-2-figs)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Diagnostic Results (1-2 figs)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q1-and-Q2\" data-toc-modified-id=\"Q1-and-Q2-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Q1 and Q2</a></span></li><li><span><a href=\"#Precipitation\" data-toc-modified-id=\"Precipitation-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Precipitation</a></span></li></ul></li><li><span><a href=\"#Equilibrium-Statistics-comparison-(3-4-figures)\" data-toc-modified-id=\"Equilibrium-Statistics-comparison-(3-4-figures)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Equilibrium Statistics comparison (3-4 figures)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prec-vs.-Lat-biases-for-NN\" data-toc-modified-id=\"Prec-vs.-Lat-biases-for-NN-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Prec vs. Lat biases for NN</a></span></li><li><span><a href=\"#Precipitation\" data-toc-modified-id=\"Precipitation-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Precipitation</a></span></li><li><span><a href=\"#Biases-in-equilibrium-state-(equator)\" data-toc-modified-id=\"Biases-in-equilibrium-state-(equator)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Biases in equilibrium state (equator)</a></span></li><li><span><a href=\"#Standard-Deviation\" data-toc-modified-id=\"Standard-Deviation-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Standard Deviation</a></span></li></ul></li><li><span><a href=\"#Transient-Comparisons\" data-toc-modified-id=\"Transient-Comparisons-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Transient Comparisons</a></span><ul class=\"toc-item\"><li><span><a href=\"#Single-Column-(1-3-figures)\" data-toc-modified-id=\"Single-Column-(1-3-figures)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Single Column (1-3 figures)</a></span></li><li><span><a href=\"#Error-growth-(equator)-(3-figures)\" data-toc-modified-id=\"Error-growth-(equator)-(3-figures)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Error growth (equator) (3 figures)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Humidity-Errors\" data-toc-modified-id=\"Humidity-Errors-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Humidity Errors</a></span></li><li><span><a href=\"#Temperature-Errors\" data-toc-modified-id=\"Temperature-Errors-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Temperature Errors</a></span></li><li><span><a href=\"#Column-Integrated-Error\" data-toc-modified-id=\"Column-Integrated-Error-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Column Integrated Error</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rc(\"image\", cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from xnoah import swap_coord, integrate\n",
    "\n",
    "import lib\n",
    "from lib import cam as lc\n",
    "from lib.plots import plot_soln\n",
    "\n",
    "from toolz.curried import valmap, get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I load the truth, SCAM and NN single column datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(best_nn=\"model.VaryNHid-256/2\"):\n",
    "\n",
    "    # Truth\n",
    "    truth = xr.open_dataset(\"../../data/processed/inputs.nc\")\n",
    "    force = xr.open_dataset(\"../../data/processed/forcings.nc\")\n",
    "    truth = truth.assign(prec=force.Prec)\n",
    "    truth = swap_coord(truth, {'z': 'p'})\n",
    "\n",
    "    # SCAM\n",
    "    # cam = xr.open_dataset(\"../data/processed/iop/0-8/cam.nc\").squeeze()\\\n",
    "    #         .sel(time=truth.time[:-10])\n",
    "\n",
    "    \n",
    "    # load and interpolate CAM\n",
    "    cam = xr.open_dataset(\"../../data/output/scam.nc\")\n",
    "    cam = lib.pressure_interp_ds(cam, truth.p)\n",
    "\n",
    "    # neural network scheme\n",
    "    nn_cols = xr.open_dataset(f\"../../data/output/{best_nn}.columns.nc\").assign(p=truth.p)\n",
    "    nn_cols = swap_coord(nn_cols, {'z': 'p'})\n",
    "    \n",
    "    # combine data\n",
    "    datasets = [truth, nn_cols, cam]\n",
    "    variables = ['qt', 'prec', 'sl']\n",
    "    time = np.unique(np.intersect1d(cam.time.values, truth.time.values))\n",
    "    data = [ds[variables].sel(time=time) for ds in datasets]\n",
    "    model_idx = pd.Index(['Truth', 'Neural Network', 'CAM'], name=\"model\")\n",
    "    ds = xr.concat(data, dim=model_idx)\n",
    "    \n",
    "    # change y coordinates\n",
    "    y = (ds.y-np.median(ds.y))\n",
    "    ds['y'] = y\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def compute_errors(metric, ds, **kwargs):\n",
    "\n",
    "    mad = {}\n",
    "    truth = ds.sel(model='Truth')\n",
    "\n",
    "    for key in ['Neural Network', 'CAM']:\n",
    "        if key in ds.model.values.tolist():\n",
    "            mad[key] = metric(truth, ds.sel(model=key), **kwargs).sortby('time')\n",
    "\n",
    "    mad['Mean'] = metric(truth, truth.mean(['x', 'time']), **kwargs).sortby('time')\n",
    "    mad['Persistence'] = metric(truth, truth.isel(time=0), **kwargs).sortby('time')\n",
    "    \n",
    "    return mad\n",
    "\n",
    "\n",
    "def mean_squared_error(truth, pred, dims=('x',)):\n",
    "    return ((truth-pred).fillna(0.0)**2).mean(dims)\n",
    "\n",
    "\n",
    "def mean_absolute_dev(truth, pred, dims=('x',)):\n",
    "    return (truth-pred).fillna(0.0).apply(np.abs).mean(dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_data()\n",
    "ds_test = ds.isel(x=slice(0, 32))\n",
    "ds_train = ds.isel(x=slice(32, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process (2 fig)\n",
    "\n",
    "I need to add some plots showing the training vs testing error for different numbers of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plots import training as tp\n",
    "\n",
    "data = tp.get_plotting_data(\"../../data/output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_parameter_sensitivity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_epochs_vs_loss(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic Results (1-2 figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 and Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibrium Statistics comparison (3-4 figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prec vs. Lat biases for NN\n",
    "\n",
    "In this section I look at the bias between the means of the neural network scheme and the time series from SAM. Running SCAM is quite expensive, so I have only run SCAM for the equatorial points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = ds_test.sel(model='Neural Network').mean(['x', 'time']) - ds_test.sel(model='Truth').mean(['x', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pres_vs_lat(bias, ax, levels=np.arange(-5, 6)*.5, title=None):\n",
    "    im = ax.contourf(bias.y, bias.p, bias, levels, cmap='bwr', extend='both')\n",
    "\n",
    "    plt.colorbar(im, pad=.01, ax=ax)\n",
    "    ax.set_xlabel('y (km)')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(7,3), dpi=100, sharey=True)\n",
    "plot_pres_vs_lat(bias.qt, axs[0], title=\"Humidity bias (g/kg)\")\n",
    "plot_pres_vs_lat(bias.sl, axs[1], title=\"Temperature bias (K)\")\n",
    "plt.subplots_adjust(wspace=.02)\n",
    "axs[0].invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation \n",
    "\n",
    "Precipitation biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = ds_test.prec.mean(['x', 'time']).to_dataset('model')\n",
    "\n",
    "plt.figure(figsize=(5, 5/1.61), dpi=100)\n",
    "\n",
    "prec['Truth'].plot(label='Truth')\n",
    "prec['Neural Network'].plot(label='NN')\n",
    "\n",
    "plt.scatter([prec.y[8]], [prec.CAM.isel(y=8)], label='CAM')\n",
    "\n",
    "plt.ylabel('Prec (mm/day)')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases in equilibrium state (equator)\n",
    "\n",
    "In this section I just show vertical profiles of the bias that NN and CAM have compared to the mean on the equator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the bias is much smaller in the neural network model than in CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ds_test.isel(y=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_sig(loc, ax=None, colors=('k', 'b', 'g')):\n",
    "    \n",
    "    dims = ['x', 'time']\n",
    "    mu = loc.mean(dims)\n",
    "    sig = loc.std(dims)\n",
    "    bias = mu-mu.sel(model='Truth')\n",
    "    \n",
    "    ds = xr.Dataset({'mu': mu, 'sig': sig, 'bias': bias})\n",
    "\n",
    "    lines = {}\n",
    "    for c, (model, val) in zip(colors, ds.groupby('model')):\n",
    "\n",
    "        # show bias only if not plotting the Truth\n",
    "        if model == 'Truth':\n",
    "            b = val.bias*np.NaN\n",
    "        else:\n",
    "            b = val.bias    \n",
    "        b = b.squeeze()\n",
    "\n",
    "        ax.plot(val.sig.squeeze(), val.p, c=c, ls='--')\n",
    "        l, = ax.plot(b, b.p, c=c)\n",
    "        # store these later for the legend\n",
    "        lines[model]= l\n",
    "    ax.set_ylim([1000, 0])\n",
    "    return lines\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(4,3), dpi=100, sharey=True,\n",
    "                        gridspec_kw=dict(wspace=0.04))\n",
    "\n",
    "lines = plot_bias_sig(loc.qt, ax=axs[0])\n",
    "lines = plot_bias_sig(loc.sl, ax=axs[1])\n",
    "axs[1].set_xlim([-2, 4])\n",
    "\n",
    "# labels and legends\n",
    "axs[0].set_title(r'$q_T$')\n",
    "axs[0].set_xlabel('(g/kg)')\n",
    "axs[0].set_ylabel('p (hPa)')\n",
    "\n",
    "axs[1].set_title(r'$s_L$')\n",
    "axs[1].set_xlabel('K')\n",
    "axs[1].legend(lines.values(), lines.keys(), bbox_to_anchor=(1.0, .9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the neural network has a similar standard deviation to the truth, whereas CAM  has much larger variability in the lower atmosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transient Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Column (1-3 figures)\n",
    "\n",
    "In this section I compare the observed time series for a given spatial location near the equator to the time series generated by forcing the neural network (NN) parametrization and the single column version of CAM.\n",
    "\n",
    "I use the three dimensional advective tendency and the surface fluxes to force both NN and CAM, I also tried to match the diurnal cycle between the runs, but I am not sure I did this perfectly yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data in ds_test.groupby('model'):\n",
    "    axs = plot_soln(data.isel(x=10, y=8))\n",
    "    \n",
    "    for ax in axs[:-1]:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        \n",
    "    axs[-1].set_ylim([-10, 150])\n",
    "    axs[-1].set_yticks([0, 50, 100])\n",
    "    plt.subplots_adjust(hspace=0.0)\n",
    "    axs[0].set_title(f\"Model: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error growth (equator) (3 figures)\n",
    "\n",
    "In this section, I plot the dynamic growth of errors after the beginning of the simulations. I do this to provide a more quantitative perspective on the pressure vs time series above.\n",
    "\n",
    "I compare the zonally averaged mean absolute deviation (MAD) for four different predictions\n",
    "\n",
    "1. MAD between the time series and its time and zonal mean. This measures the magnitude of the fluctuations about the climatology.\n",
    "2. Persistence forecast. This forecast assumes that humidity and temperature do not change over the course of the simulation. This gives us an estimate of the time-scale over which the fields change naturally.\n",
    "3. SCAM based prediction\n",
    "4. NN based prediction\n",
    "\n",
    "I only do this at the equator because the sCAM simulation is too expensive to run for the whole domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mses(mses, axs=None, label='',\n",
    "              n_days=40,\n",
    "              **kwargs):\n",
    "    if axs is None:\n",
    "        fig, axs =plt.subplots(2, 2, sharey=True, sharex=True, dpi=100,\n",
    "                              figsize=(6, 3.5))\n",
    "        \n",
    "    keys = mses.keys()\n",
    "    \n",
    "    for ax, key in zip(axs.flat, keys):\n",
    "        val = mses[key]\n",
    "        im = ax.contourf(val.time, val.p, val.T, **kwargs)\n",
    "\n",
    "        ax.text(.05, .8, key,\n",
    "                transform=ax.transAxes,\n",
    "                color='white', fontsize=13)\n",
    "        \n",
    "    \n",
    "    axs[0,0].invert_yaxis()\n",
    "    axs[0,0].set_ylabel('p (hPa)')\n",
    "    axs[1,0].set_ylabel('p (hPa)')\n",
    "    \n",
    "    for ax in axs[1,:]:\n",
    "        ax.set_xlabel('days')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=.02, hspace=.02)\n",
    "    cb = plt.colorbar(im, ax=axs, pad=.01)\n",
    "    cb.set_label(label)\n",
    "    \n",
    "    axs[0,0].set_xlim([val.time.min(), val.time.min()+ n_days])\n",
    "    \n",
    "    return axs, cb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humidity Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = compute_errors(mean_absolute_dev, ds_test.isel(y=8), dims=['x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_qt = valmap(get('qt'), mad)\n",
    "_, cb = plot_mses(mad_qt, levels=np.arange(11)*.25,\n",
    "                  extend='max',\n",
    "                  label='MAD (g/kg)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see errors grow much more slowly for NN than for the other quantities. In practice, the NN is able to predict around 5-7 days before it decays to the mean. This is much vetter than either the persistence forecast or CAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_sl = valmap(get('sl'), mad)\n",
    "plot_mses(mad_sl, levels=.5*np.arange(11), extend='max',\n",
    "          label='MAD (K)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature predicted by the NN diverges from the truth much faster that it does for the humidity. Some large biases in the temperature emerge in the NN and CAM schemes.  Moreover, it appears the neural network misses the diurnal cycle of temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Integrated Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_no_cam = ds_test.drop('CAM', dim='model').sel(y=slice(-400e3, 400e3))\n",
    "\n",
    "mad = compute_errors(mean_absolute_dev, ds_no_cam, dims=['x'])\n",
    "mad_sl = valmap(get('sl'), mad)\n",
    "mad_qt = valmap(get('qt'), mad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_mad_sl = xr.Dataset({k: -integrate(v, 'p')/1015 for k, v in mad_sl.items()}).mean('y').to_dataframe()\n",
    "mass_mad_qt = xr.Dataset({k: -integrate(v, 'p')/1015 for k, v in mad_qt.items()}).mean('y').to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.rc_context({'axes.prop_cycle': plt.cycler('color', 'kbgy'),\n",
    "                     'lines.linewidth': 1.0,\n",
    "                    }):\n",
    "\n",
    "    fig, (axT, axQ) = plt.subplots(1, 2, figsize=(7,3), dpi=100, sharex=True)\n",
    "\n",
    "    mass_mad_sl.plot(ax=axT, legend=False)\n",
    "    axT.set_ylabel(r'vMAD (K)')\n",
    "\n",
    "    mass_mad_qt.plot(ax=axQ)\n",
    "    axQ.set_ylabel(r'vMAD (g/kg)')\n",
    "    axT.set_xlim([100, 180])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "166px",
    "width": "370px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 939.77778,
   "position": {
    "height": "40px",
    "left": "1835.56px",
    "right": "20px",
    "top": "120px",
    "width": "394px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
