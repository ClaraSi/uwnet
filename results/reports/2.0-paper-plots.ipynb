{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-process-(2-fig)\" data-toc-modified-id=\"Training-process-(2-fig)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training process (2 fig)</a></span></li><li><span><a href=\"#Diagnostic-Results-(1-2-figs)\" data-toc-modified-id=\"Diagnostic-Results-(1-2-figs)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Diagnostic Results (1-2 figs)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Q1-and-Q2\" data-toc-modified-id=\"Q1-and-Q2-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Q1 and Q2</a></span></li><li><span><a href=\"#Precipitation\" data-toc-modified-id=\"Precipitation-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Precipitation</a></span></li></ul></li><li><span><a href=\"#Equilibrium-Statistics-comparison-(3-4-figures)\" data-toc-modified-id=\"Equilibrium-Statistics-comparison-(3-4-figures)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Equilibrium Statistics comparison (3-4 figures)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prec-vs.-Lat-biases-for-NN\" data-toc-modified-id=\"Prec-vs.-Lat-biases-for-NN-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Prec vs. Lat biases for NN</a></span></li><li><span><a href=\"#Precipitation\" data-toc-modified-id=\"Precipitation-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Precipitation</a></span></li><li><span><a href=\"#Biases-in-equilibrium-state-(equator)\" data-toc-modified-id=\"Biases-in-equilibrium-state-(equator)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Biases in equilibrium state (equator)</a></span></li><li><span><a href=\"#Standard-Deviation\" data-toc-modified-id=\"Standard-Deviation-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Standard Deviation</a></span></li></ul></li><li><span><a href=\"#Transient-Comparisons\" data-toc-modified-id=\"Transient-Comparisons-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Transient Comparisons</a></span><ul class=\"toc-item\"><li><span><a href=\"#Single-Column-(1-3-figures)\" data-toc-modified-id=\"Single-Column-(1-3-figures)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Single Column (1-3 figures)</a></span></li><li><span><a href=\"#Error-growth-(equator)-(3-figures)\" data-toc-modified-id=\"Error-growth-(equator)-(3-figures)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Error growth (equator) (3 figures)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Humidity-Errors\" data-toc-modified-id=\"Humidity-Errors-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Humidity Errors</a></span></li><li><span><a href=\"#Temperature-Errors\" data-toc-modified-id=\"Temperature-Errors-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Temperature Errors</a></span></li><li><span><a href=\"#Column-Integrated-Error\" data-toc-modified-id=\"Column-Integrated-Error-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Column Integrated Error</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import holoviews as hv\n",
    "hv.extension('matplotlib')\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rc(\"image\", cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from xnoah import swap_coord\n",
    "from lib.plots import plot_soln\n",
    "import lib\n",
    "from lib import cam as lc\n",
    "import glob\n",
    "from toolz import valmap\n",
    "from toolz.curried import get\n",
    "\n",
    "from xnoah import integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I load the truth, SCAM and NN single column datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    # Truth\n",
    "    truth = xr.open_dataset(\"../../data/processed/inputs.nc\")\n",
    "    force = xr.open_dataset(\"../../data/processed/forcings.nc\")\n",
    "    truth = truth.assign(prec=force.Prec)\n",
    "    truth = swap_coord(truth, {'z': 'p'})\n",
    "\n",
    "    # SCAM\n",
    "    # cam = xr.open_dataset(\"../data/processed/iop/0-8/cam.nc\").squeeze()\\\n",
    "    #         .sel(time=truth.time[:-10])\n",
    "\n",
    "    \n",
    "    # load and interpolate CAM\n",
    "    cam = xr.open_dataset(\"../../data/output/scam.nc\")\n",
    "    cam = lib.pressure_interp_ds(cam, truth.p)\n",
    "\n",
    "    # neural network scheme\n",
    "    nn_cols = xr.open_dataset(\"../../data/output/model.VaryNHid-256/7.columns.nc\").assign(p=truth.p)\n",
    "    nn_cols = swap_coord(nn_cols, {'z': 'p'})\n",
    "    \n",
    "    # combine data\n",
    "    datasets = [truth, nn_cols, cam]\n",
    "    variables = ['qt', 'prec', 'sl']\n",
    "    time = np.unique(np.intersect1d(cam.time.values, truth.time.values))\n",
    "    data = [ds[variables].sel(time=time) for ds in datasets]\n",
    "    model_idx = pd.Index(['Truth', 'Neural Network', 'CAM'], name=\"model\")\n",
    "    ds = xr.concat(data, dim=model_idx)\n",
    "    \n",
    "    # change y coordinates\n",
    "    y = (ds.y-np.median(ds.y))\n",
    "    ds['y'] = y\n",
    "\n",
    "    return ds\n",
    "    \n",
    "\n",
    "\n",
    "def compute_errors(metric, ds, **kwargs):\n",
    "\n",
    "    mad = {}\n",
    "    truth = ds.sel(model='Truth')\n",
    "\n",
    "    for key in ['Neural Network', 'CAM']:\n",
    "        mad[key] = metric(truth, ds.sel(model=key), **kwargs).sortby('time')\n",
    "\n",
    "    mad['Mean'] = metric(truth, truth.mean(['x', 'time']), **kwargs).sortby('time')\n",
    "    mad['Persistence'] = metric(truth, truth.isel(time=0), **kwargs).sortby('time')\n",
    "    \n",
    "    return mad\n",
    "\n",
    "\n",
    "def mean_squared_error(truth, pred, dims=('x',)):\n",
    "    return ((truth-pred).fillna(0.0)**2).mean(dims)\n",
    "\n",
    "\n",
    "def mean_absolute_dev(truth, pred, dims=('x',)):\n",
    "    return (truth-pred).fillna(0.0).apply(np.abs).mean(dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process (2 fig)\n",
    "\n",
    "I need to add some plots showing the training vs testing error for different numbers of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plots import training as tp\n",
    "\n",
    "data = tp.get_plotting_data(\"../../data/output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_parameter_sensitivity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.plot_epochs_vs_loss(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic Results (1-2 figs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 and Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibrium Statistics comparison (3-4 figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prec vs. Lat biases for NN\n",
    "\n",
    "In this section I look at the bias between the means of the neural network scheme and the time series from SAM. Running SCAM is quite expensive, so I have only run SCAM for the equatorial points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pres_vs_lat(bias, ax, levels=np.arange(-5, 6)*.5, title=None):\n",
    "    im = ax.contourf(bias.y, bias.p, bias, levels, cmap='bwr', extend='both')\n",
    "\n",
    "    plt.colorbar(im, pad=.01, ax=ax)\n",
    "    ax.set_xlabel('y (km)')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    \n",
    "bias = ds.sel(model='Neural Network').mean(['x', 'time']) - ds.sel(model='Truth').mean(['x', 'time'])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(7,3), dpi=100, sharey=True)\n",
    "plot_pres_vs_lat(bias.qt, axs[0], title=\"Humidity bias (g/kg)\")\n",
    "plot_pres_vs_lat(bias.sl, axs[1], title=\"Temperature bias (K)\")\n",
    "plt.subplots_adjust(wspace=.02)\n",
    "axs[0].invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation \n",
    "\n",
    "Precipitation biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = ds.prec.mean(['x', 'time']).to_dataset('model')\n",
    "\n",
    "plt.figure(figsize=(5, 5/1.61), dpi=100)\n",
    "\n",
    "prec['Truth'].plot(label='Truth')\n",
    "prec['Neural Network'].plot(label='NN')\n",
    "\n",
    "plt.scatter([prec.y[8]], [prec.CAM.isel(y=8)], label='CAM')\n",
    "\n",
    "plt.ylabel('Prec (mm/day)')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases in equilibrium state (equator)\n",
    "\n",
    "In this section I just show vertical profiles of the bias that NN and CAM have compared to the mean on the equator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias(ds, ax=None, title=\"\", xlim=None, unit=None):\n",
    "    obs = ds.sel(model='Truth')\n",
    "    ds = ds.sel(model=['Neural Network', 'CAM'])\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1, figsize=(2,3), dpi=100)\n",
    "\n",
    "    for key, val in ds.groupby('model'):\n",
    "        ax.plot(val.squeeze()-obs, val.p, label=key)\n",
    "    ax.set_title(title, size=10)\n",
    "    if xlim:\n",
    "        ax.set_xlim(xlim)\n",
    "    if unit:\n",
    "        ax.set_xlabel(unit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the bias is much smaller in the neural network model than in CAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ds.isel(y=8).mean(['x', 'time'])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(4,3), dpi=100, sharey=True)\n",
    "plot_bias(loc.qt, title='Total water bias', unit='g/kg',\n",
    "          ax=axs[0], xlim=[-1, 1])\n",
    "plot_bias(loc.sl, title='Temperature bias', unit='K',\n",
    "          ax=axs[1], xlim=[-2, 2])\n",
    "\n",
    "\n",
    "axs[0].invert_yaxis()\n",
    "axs[0].set_ylabel('p (hPa)')\n",
    "axs[1].legend()\n",
    "axs[1].set_ylim([1000, 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = ['x', 'time']\n",
    "sig = ds.std(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[invert_yaxis=True, invert_axes=True] {+framewise}\n",
    "\n",
    "(hv.Dataset(sig.qt)\n",
    " .to.curve(\"p\")\n",
    " .overlay(\"model\")\n",
    " .redim.unit(qt=\"g/kg\", p=\"hPa\")\n",
    " .redim.label(qt=r\"$q_T$\")\n",
    " \n",
    " + hv.Dataset(sig.sl)\n",
    " .to.curve(\"p\")\n",
    " .overlay(\"model\")\n",
    " .redim.unit(sl=\"K\", p=\"hPa\")\n",
    ".redim.label(sl=r\"$s_L$\"))\\\n",
    ".redim.unit(y=\"1000 km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the neural network has a similar standard deviation to the truth, whereas CAM  has much larger variability in the lower atmosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transient Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Column (1-3 figures)\n",
    "\n",
    "In this section I compare the observed time series for a given spatial location near the equator to the time series generated by forcing the neural network (NN) parametrization and the single column version of CAM.\n",
    "\n",
    "I use the three dimensional advective tendency and the surface fluxes to force both NN and CAM, I also tried to match the diurnal cycle between the runs, but I am not sure I did this perfectly yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data in ds.groupby('model'):\n",
    "    axs = plot_soln(data.isel(x=0, y=8))\n",
    "    \n",
    "    for ax in axs[:-1]:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        \n",
    "    axs[-1].set_ylim([-10, 150])\n",
    "    axs[-1].set_yticks([0, 50, 100])\n",
    "    plt.subplots_adjust(hspace=0.0)\n",
    "    axs[0].set_title(f\"Model: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error growth (equator) (3 figures)\n",
    "\n",
    "In this section, I plot the dynamic growth of errors after the beginning of the simulations. I do this to provide a more quantitative perspective on the pressure vs time series above.\n",
    "\n",
    "I compare the zonally averaged mean absolute deviation (MAD) for four different predictions\n",
    "\n",
    "1. MAD between the time series and its time and zonal mean. This measures the magnitude of the fluctuations about the climatology.\n",
    "2. Persistence forecast. This forecast assumes that humidity and temperature do not change over the course of the simulation. This gives us an estimate of the time-scale over which the fields change naturally.\n",
    "3. SCAM based prediction\n",
    "4. NN based prediction\n",
    "\n",
    "I only do this at the equator because the sCAM simulation is too expensive to run for the whole domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mses(mses, axs=None, label='', **kwargs):\n",
    "    if axs is None:\n",
    "        fig, axs =plt.subplots(2, 2, sharey=True, sharex=True, dpi=100,\n",
    "                              figsize=(6, 3.5))\n",
    "        \n",
    "    keys = mses.keys()\n",
    "    \n",
    "    for ax, key in zip(axs.flat, keys):\n",
    "        val = mses[key]\n",
    "        im = ax.contourf(val.time, val.p, val.T, **kwargs)\n",
    "\n",
    "        ax.text(.05, .8, key,\n",
    "                transform=ax.transAxes,\n",
    "                color='white', fontsize=13)\n",
    "        \n",
    "    \n",
    "    axs[0,0].invert_yaxis()\n",
    "    axs[0,0].set_ylabel('p (hPa)')\n",
    "    axs[1,0].set_ylabel('p (hPa)')\n",
    "    \n",
    "    for ax in axs[1,:]:\n",
    "        ax.set_xlabel('days')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=.02, hspace=.02)\n",
    "    cb = plt.colorbar(im, ax=axs, pad=.01)\n",
    "    cb.set_label(label)\n",
    "    \n",
    "    axs[0,0].set_xlim([val.time.min(), val.time.min()+ 20])\n",
    "    \n",
    "    return axs, cb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humidity Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad = compute_errors(mean_absolute_dev, ds.isel(y=8), dims=['x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_qt = valmap(get('qt'), mad)\n",
    "_, cb = plot_mses(mad_qt, levels=np.arange(11)*.25,\n",
    "                  extend='max',\n",
    "                  label='MAD (g/kg)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see errors grow much more slowly for NN than for the other quantities. In practice, the NN is able to predict around 5-7 days before it decays to the mean. This is much vetter than either the persistence forecast or CAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_sl = valmap(get('sl'), mad)\n",
    "plot_mses(mad_sl, levels=.5*np.arange(11), extend='max',\n",
    "          label='MAD (K)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature predicted by the NN diverges from the truth much faster that it does for the humidity. Some large biases in the temperature emerge in the NN and CAM schemes.  Moreover, it appears the neural network misses the diurnal cycle of temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Integrated Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (axT, axQ) = plt.subplots(1, 2, figsize=(7,3), dpi=100)\n",
    "mass_mad_sl = xr.Dataset({k: -integrate(v, 'p')/1015 for k, v in mad_sl.items()}).to_dataframe()\n",
    "mass_mad_qt = xr.Dataset({k: -integrate(v, 'p')/1015 for k, v in mad_qt.items()}).to_dataframe()\n",
    "\n",
    "mass_mad_sl.plot(ax=axT, legend=False)\n",
    "axT.set_ylabel(r'vMAD (K)')\n",
    "\n",
    "mass_mad_qt.plot(ax=axQ)\n",
    "axQ.set_ylabel(r'vMAD (g/kg)')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "166px",
    "width": "370px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "334px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 939.77778,
   "position": {
    "height": "40px",
    "left": "1835.56px",
    "right": "20px",
    "top": "120px",
    "width": "394px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
