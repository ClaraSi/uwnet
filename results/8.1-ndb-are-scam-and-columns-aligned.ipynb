{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "from matplotlib import cycler\n",
    "from xnoah import swap_coord\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "plt.style.use([\"noah\", \"seaborn-darkgrid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was having a problem with the SCAM, IOP, and NN data not being aligned in the 2.0-paper-plots notebook. I suspect that this is because the time coordinate is not aligned between the different datasets. For the CAM runs, I chose the 1999-01-01 as the arbitrary start date of the simulation as you can see here. First let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = xr.open_dataset(\"../data/output/columns.nc\")\n",
    "scam = xr.open_dataset(\"../data/output/scam.nc\")\n",
    "iop = xr.open_dataset(\"../data/processed/iop.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the start date of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iop.bdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure these data are defined on the same horizontal coordinates, 'x',  and 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iop = swap_coord(iop, {'lon': 'x', 'lat': 'y'})\n",
    "nn = nn.sel(y=scam.y).assign_coords()\n",
    "iop = iop.sel(y=scam.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make the time coordinates of iop, scam and nn match. I am just going to convert the nn and iop to have date formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdate = np.datetime64('1999-01-01')\n",
    "time = (nn.time.values  * 86400).astype('timedelta64[s]') + bdate\n",
    "\n",
    "nn = nn.assign_coords(time=time)\n",
    "iop = iop.assign_coords(tsec=time).rename({'tsec': 'time'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data are aligned in time, we should convert the time coordinates back to days from simulation start, because the dates have no significance. We only used the dates to help align the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dates_to_days(bdate, x):\n",
    "    time = x.time.values - bdate\n",
    "    time = time.astype('timedelta64[s]').astype(float)/86400\n",
    "    return x.assign_coords(time=time)\n",
    "\n",
    "\n",
    "iop, nn, scam = [convert_dates_to_days(bdate, f) for f in [iop, nn, scam]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to broadcast all the precip fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset({\n",
    "    'nn': nn.prec,\n",
    "    'cam': scam.prec,\n",
    "    'iop': iop.PREC\n",
    "}).dropna('time')\\\n",
    ".squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_array().plot(col='variable', figsize=(3*3, 3*1.61), cmap='inferno_r', vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the models all do a pretty good job of capturing the wave-like structure of the precipitation field. In fact the Neural network model seems to be worse the SCAM at capturing the precipitation peaks. This is clearer when we plot the time series for a single spatial location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = ds.isel(x=0).to_dataframe().drop(['x' ,'y'], 1)\\\n",
    ".plot(markevery=10, color='k', subplots=True)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_yticks(np.arange(0, 200, 50));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, CAM overstimates many of the peaks in precipitation. This is probably because CAM listens to the erroneous forcing data more than the Neural network scheme, which has learned to overcome the errors in the forcings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
